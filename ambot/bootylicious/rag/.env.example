# =============================================================================
# Ambot RAG System - Environment Configuration
# =============================================================================
# Copy this file to .env and customize as needed
# cp .env.example .env
# =============================================================================

# -----------------------------------------------------------------------------
# Network
# -----------------------------------------------------------------------------
NETWORK_NAME=ambot-rag
API_PORT=8000

# -----------------------------------------------------------------------------
# PostgreSQL
# -----------------------------------------------------------------------------
POSTGRES_DB=ambot_rag
POSTGRES_USER=ambot
POSTGRES_PASSWORD=ambot_secure_pass

# -----------------------------------------------------------------------------
# Embedding Model
# -----------------------------------------------------------------------------
# Using sentence-transformers (runs locally in API container)
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
EMBEDDING_BACKEND=sentence-transformers

# -----------------------------------------------------------------------------
# Chunking
# -----------------------------------------------------------------------------
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# -----------------------------------------------------------------------------
# LLM Backend
# -----------------------------------------------------------------------------
# Options: "ollama" or "huggingface"
# - ollama: Connects to external Ollama server
# - huggingface: Runs model locally with transformers
LLM_BACKEND=ollama

# -----------------------------------------------------------------------------
# Ollama Configuration (if LLM_BACKEND=ollama)
# -----------------------------------------------------------------------------
OLLAMA_BASE_URL=http://host.docker.internal:11434
LLM_MODEL=tinyllama
LLM_TEMPERATURE=0.3
LLM_TIMEOUT=300

# -----------------------------------------------------------------------------
# HuggingFace Configuration (if LLM_BACKEND=huggingface)
# -----------------------------------------------------------------------------
HF_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
HF_DEVICE=cuda
HF_TORCH_DTYPE=float16
HF_CACHE=~/.cache/huggingface

# -----------------------------------------------------------------------------
# RAG Retrieval
# -----------------------------------------------------------------------------
RAG_TOP_K=3
RAG_MIN_SIMILARITY=0.75

# -----------------------------------------------------------------------------
# Project
# -----------------------------------------------------------------------------
PROJECT_NAME=ambot-eecs

# -----------------------------------------------------------------------------
# Knowledge Base
# -----------------------------------------------------------------------------
# Directory containing documents to ingest
KNOWLEDGE_DIR=./knowledge
